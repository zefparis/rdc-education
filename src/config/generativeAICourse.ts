import { Module } from './enhancedCourseConfig';

export const generativeAICourse: Module = {
  id: '4',
  slug: 'ia-generative',
  title: 'Intelligence Artificielle G√©n√©rative',
  description: 'Cr√©ez du contenu avec l\'IA : texte (GPT), images (DALL¬∑E), audio (TTS) et combinez les modalit√©s pour des applications innovantes.',
  duration: '8 semaines',
  level: 'Interm√©diaire',
  icon: 'üé®',
  color: 'from-orange-500 to-red-500',
  image: '/images/ia-generative.jpg',
  pdf: '/modules/ia-generative/README.md',
  notebook: '/modules/ia-generative/module-ia-generative.ipynb',
  audio: '/audio/module_ia-generative.mp3',
  colabUrl: 'https://colab.research.google.com/github/ia-solution-rdc/genai/blob/main/module-genai.ipynb',
  objectives: [
    'Comprendre les principes de l\'IA g√©n√©rative',
    'Ma√Ætriser les mod√®les de g√©n√©ration de texte (GPT)',
    'Cr√©er des images avec l\'IA (DALL¬∑E, Stable Diffusion)',
    'G√©n√©rer de l\'audio et de la musique',
    'Combiner plusieurs modalit√©s (texte, image, audio)',
    'D√©velopper des applications cr√©atives avec l\'IA',
    'Comprendre les enjeux √©thiques et l√©gaux'
  ],
  prerequisites: [
    'Bases solides en Python et Machine Learning',
    'Compr√©hension du Deep Learning (TensorFlow/Keras)',
    'Notions de traitement du langage naturel',
    'Connaissance de l\'alg√®bre lin√©aire'
  ],
  sections: [
    {
      id: 'generative-ai-fundamentals',
      title: 'Principes fondamentaux de l\'IA g√©n√©rative',
      content: `
        <div class="course-section">
          <h3>Qu'est-ce que l'IA g√©n√©rative ?</h3>
          <p>L'IA g√©n√©rative d√©signe les syst√®mes d'intelligence artificielle capables de cr√©er du contenu original : texte, images, audio, vid√©os, code, etc. Contrairement aux mod√®les discriminatifs qui classifient ou pr√©disent, les mod√®les g√©n√©ratifs apprennent les patterns des donn√©es pour cr√©er du nouveau contenu.</p>

          <h4>Paradigmes de g√©n√©ration :</h4>
          <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 20px 0;">
            <div style="padding: 15px; background-color: #e6f3ff; border-radius: 8px; border-left: 4px solid #0066cc;">
              <h5 style="color: #0066cc; margin-top: 0;">üìù G√©n√©ration de texte</h5>
              <p>Mod√®les de langage comme GPT</p>
              <ul>
                <li>Traduction automatique</li>
                <li>R√©daction d'articles</li>
                <li>Chatbots conversationnels</li>
              </ul>
            </div>
            <div style="padding: 15px; background-color: #fff0f5; border-radius: 8px; border-left: 4px solid #ff69b4;">
              <h5 style="color: #ff69b4; margin-top: 0;">üé® G√©n√©ration d'images</h5>
              <p>Mod√®les de diffusion comme DALL¬∑E</p>
              <ul>
                <li>Cr√©ation artistique</li>
                <li>Design graphique</li>
                <li>Illustration automatique</li>
              </ul>
            </div>
            <div style="padding: 15px; background-color: #f0fff0; border-radius: 8px; border-left: 4px solid #32cd32;">
              <h5 style="color: #32cd32; margin-top: 0;">üéµ G√©n√©ration audio</h5>
              <p>Synth√®se vocale et musicale</p>
              <ul>
                <li>Text-to-Speech (TTS)</li>
                <li>Composition musicale</li>
                <li>Clonage de voix</li>
              </ul>
            </div>
          </div>

          <h3>Fonctionnement des mod√®les g√©n√©ratifs</h3>
          <h4>1. Apprentissage des distributions</h4>
          <p>Les mod√®les g√©n√©ratifs apprennent la distribution de probabilit√© des donn√©es d'entra√Ænement pour pouvoir √©chantillonner de nouvelles donn√©es r√©alistes.</p>

          <h4>2. Maximum de vraisemblance</h4>
          <p>L'objectif est de maximiser la probabilit√© que le mod√®le g√©n√®re des donn√©es similaires √† celles d'entra√Ænement.</p>

          <h4>3. Techniques d'√©chantillonnage</h4>
          <ul>
            <li><strong>Greedy decoding :</strong> Choix du token le plus probable</li>
            <li><strong>Beam search :</strong> Exploration de plusieurs s√©quences</li>
            <li><strong>Top-k sampling :</strong> √âchantillonnage parmi les k tokens les plus probables</li>
            <li><strong>Nucleus sampling :</strong> √âchantillonnage dynamique selon la masse de probabilit√©</li>
          </ul>

          <div class="warning-box">
            <strong>‚ö†Ô∏è Consid√©rations √©thiques :</strong> L'IA g√©n√©rative soul√®ve des questions importantes sur la propri√©t√© intellectuelle, les deepfakes, et l'impact sur l'emploi.
          </div>
        </div>
      `,
      order: 1,
      estimatedTime: '2h',
      codeExamples: [
        {
          title: 'Introduction √† la g√©n√©ration de texte avec GPT-2',
          description: 'Premiers pas avec un mod√®le de langage pour g√©n√©rer du texte',
          code: `import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import warnings
warnings.filterwarnings('ignore')

print("ü§ñ Initialisation du mod√®le GPT-2...")

# Chargement du mod√®le et du tokenizer
model_name = "gpt2"  # Version l√©g√®re pour d√©buter
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Configuration pour l'√©valuation
model.eval()

def generate_text(prompt, max_length=100, temperature=0.7):
    """
    G√©n√®re du texte √† partir d'un prompt

    Args:
        prompt: Texte de d√©part
        max_length: Longueur maximale du texte g√©n√©r√©
        temperature: Contr√¥le de la cr√©ativit√© (0.1 = conservateur, 1.0 = cr√©atif)
    """
    # Tokenization du prompt
    input_ids = tokenizer.encode(prompt, return_tensors="pt")

    # G√©n√©ration avec contr√¥le de temp√©rature
    with torch.no_grad():
        output = model.generate(
            input_ids,
            max_length=max_length,
            temperature=temperature,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            pad_token_id=tokenizer.eos_token_id,
            do_sample=True,
            top_k=50,
            top_p=0.95
        )

    # D√©codage du texte g√©n√©r√©
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

    return generated_text

# Tests de g√©n√©ration
print("\\nüìù Test 1 - G√©n√©ration cr√©ative")
prompt1 = "L'intelligence artificielle va r√©volutionner"
result1 = generate_text(prompt1, max_length=150, temperature=0.8)
print(f"Prompt: {prompt1}")
print(f"G√©n√©r√©: {result1}\\n")

print("üìù Test 2 - Suite d'histoire")
prompt2 = "Dans un monde o√π les robots vivent parmi les humains"
result2 = generate_text(prompt2, max_length=120, temperature=0.7)
print(f"Prompt: {prompt2}")
print(f"G√©n√©r√©: {result2}\\n")

print("üìù Test 3 - R√©ponse technique")
prompt3 = "Comment cr√©er un mod√®le de machine learning ?"
result3 = generate_text(prompt3, max_length=180, temperature=0.6)
print(f"Prompt: {prompt3}")
print(f"G√©n√©r√©: {result3}\\n")

# Comparaison des temp√©ratures
print("üå°Ô∏è Comparaison des temp√©ratures:")
for temp in [0.1, 0.5, 0.9]:
    result = generate_text("Le futur de l'IA", max_length=80, temperature=temp)
    print(f"Temp√©rature {temp}: {result}")`,
          language: 'python',
          explanation: 'Ce code montre comment utiliser un mod√®le GPT-2 pr√©-entra√Æn√© pour g√©n√©rer du texte de mani√®re contr√¥l√©e avec diff√©rents niveaux de cr√©ativit√©.'
        }
      ],
      exercises: [
        {
          id: 'ex-gpt-prompt-engineering',
          title: 'Ing√©nierie des prompts',
          description: 'Exp√©rimentez diff√©rents types de prompts pour am√©liorer la qualit√© de g√©n√©ration de texte.',
          difficulty: 'facile',
          solution: `# Diff√©rentes techniques de prompt engineering

prompts = [
    "√âcris une histoire courte sur un robot bienveillant",
    "Raconte-moi une histoire courte. Th√®me: robot bienveillant. Style: conte pour enfants",
    "Histoire courte:\\nProtagoniste: Robot bienveillant\\nIntrigue: D√©couverte d'un jardin secret\\nFin: Le√ßon d'amiti√©",
    "Tu es un auteur de contes pour enfants. √âcris une histoire de 100 mots sur un robot qui d√©couvre un jardin magique avec des fleurs qui chantent."
]

for i, prompt in enumerate(prompts, 1):
    print(f"\\n--- Prompt {i} ---")
    print(f"Prompt: {prompt}")
    result = generate_text(prompt, max_length=150, temperature=0.7)
    print(f"R√©sultat: {result}")`
        }
      ],
      resources: [
        {
          title: 'Attention Is All You Need - Paper fondateur des transformers',
          type: 'article',
          url: 'https://arxiv.org/abs/1706.03762'
        },
        {
          title: 'The Illustrated GPT-2',
          type: 'article',
          url: 'https://jalammar.github.io/illustrated-gpt2/'
        },
        {
          title: 'Hugging Face Transformers',
          type: 'documentation',
          url: 'https://huggingface.co/docs/transformers/'
        }
      ]
    },
    {
      id: 'text-generation-models',
      title: 'Mod√®les avanc√©s de g√©n√©ration de texte',
      content: `
        <div class="course-section">
          <h3>L'architecture Transformer</h3>
          <p>Les transformers sont devenus l'architecture dominante pour le traitement du langage naturel gr√¢ce √† leur m√©canisme d'attention qui permet de traiter les d√©pendances √† longue port√©e efficacement.</p>

          <h4>Composants cl√©s d'un Transformer :</h4>
          <ul>
            <li><strong>Attention multi-t√™te :</strong> Plusieurs m√©canismes d'attention en parall√®le</li>
            <li><strong>Encodeur-D√©codeur :</strong> Architecture s√©quence-√†-s√©quence</li>
            <li><strong>Positionnal encoding :</strong> Encodage de l'ordre des mots</li>
            <li><strong>Feed-forward networks :</strong> Transformation non-lin√©aire</li>
          </ul>

          <h3>GPT : Generative Pre-trained Transformer</h3>
          <p>GPT est un mod√®le g√©n√©ratif bas√© uniquement sur le d√©codeur du transformer original, pr√©-entra√Æn√© sur d'√©normes quantit√©s de texte.</p>

          <h4>√âvolution de GPT :</h4>
          <ul>
            <li><strong>GPT-1 (2018) :</strong> 117M param√®tres</li>
            <li><strong>GPT-2 (2019) :</strong> 1.5B param√®tres</li>
            <li><strong>GPT-3 (2020) :</strong> 175B param√®tres</li>
            <li><strong>GPT-4 (2023) :</strong> Param√®tres non divulgu√©s (estim√©s >1T)</li>
          </ul>

          <h3>Techniques avanc√©es</h3>
          <h4>Fine-tuning</h4>
          <p>Adaptation d'un mod√®le pr√©-entra√Æn√© √† une t√¢che sp√©cifique avec un petit dataset.</p>

          <h4>Prompt engineering</h4>
          <p>Art de concevoir des prompts efficaces pour obtenir de meilleurs r√©sultats.</p>

          <h4>Few-shot learning</h4>
          <p>Apprentissage avec tr√®s peu d'exemples gr√¢ce au pr√©-entra√Ænement massif.</p>
        </div>
      `,
      order: 2,
      estimatedTime: '3h',
      codeExamples: [
        {
          title: 'Fine-tuning d\'un mod√®le de langage',
          description: 'Adaptation d\'un mod√®le GPT √† une t√¢che sp√©cifique avec un petit dataset',
          code: `import torch
from torch.utils.data import Dataset, DataLoader
from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup
import pandas as pd
import numpy as np

# 1. Pr√©paration d'un petit dataset pour le fine-tuning
class TextDataset(Dataset):
    def __init__(self, texts, tokenizer, max_length=128):
        self.texts = texts
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]

        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten()
        }

# Dataset d'exemple : g√©n√©ration de descriptions de produits
product_descriptions = [
    "Smartphone derni√®re g√©n√©ration avec cam√©ra 108MP et batterie 5000mAh",
    "Ordinateur portable ultral√©ger parfait pour les d√©veloppeurs",
    "Casque audio sans fil avec r√©duction de bruit active",
    "Montre connect√©e avec suivi de sant√© et GPS int√©gr√©",
    "Tablette graphique professionnelle pour artistes num√©riques"
]

# Ajout de prompts pour l'entra√Ænement
training_texts = []
for desc in product_descriptions:
    # Format : "Produit : [description]"
    training_texts.append(f"Produit : {desc}")

print(f"üìö Dataset d'entra√Ænement: {len(training_texts)} exemples")

# 2. Configuration du mod√®le
model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Ajout du token de padding
tokenizer.pad_token = tokenizer.eos_token

# 3. Pr√©paration des donn√©es
dataset = TextDataset(training_texts, tokenizer)
dataloader = DataLoader(dataset, batch_size=2, shuffle=True)

# 4. Configuration de l'optimisation
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(
    optimizer, num_warmup_steps=0, num_training_steps=len(dataloader) * 3
)

# 5. Entra√Ænement (version simplifi√©e)
model.train()
epochs = 3

for epoch in range(epochs):
    total_loss = 0

    for batch in dataloader:
        optimizer.zero_grad()

        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)

        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)
        loss = outputs.loss

        loss.backward()
        optimizer.step()
        scheduler.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(dataloader)
    print(f"√âpoque {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}")

print("\\n‚úÖ Fine-tuning termin√©!")

# 6. Test du mod√®le fine-tun√©
def generate_product_description(prompt, model, tokenizer, max_length=100):
    model.eval()

    input_text = f"Produit : {prompt}"
    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)

    with torch.no_grad():
        output = model.generate(
            input_ids,
            max_length=max_length,
            temperature=0.7,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            pad_token_id=tokenizer.eos_token_id
        )

    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    return generated_text

# Tests
test_prompts = [
    "Cam√©ra professionnelle",
    "V√©hicule √©lectrique autonome",
    "Intelligence artificielle"
]

print("\\nüõçÔ∏è G√©n√©ration de descriptions de produits:")
for prompt in test_prompts:
    description = generate_product_description(prompt, model, tokenizer)
    print(f"\\nPrompt: {prompt}")
    print(f"G√©n√©r√©: {description}")`,
          language: 'python',
          explanation: 'Ce code montre comment fine-tuner un mod√®le GPT-2 sur un petit dataset sp√©cifique pour g√©n√©rer des descriptions de produits personnalis√©es.'
        }
      ],
      exercises: [
        {
          id: 'ex-fine-tuning-custom',
          title: 'Fine-tuning pour g√©n√©ration de po√©sie',
          description: 'Adaptez un mod√®le GPT pour g√©n√©rer des po√®mes dans un style sp√©cifique.',
          difficulty: 'moyen',
          solution: `# Dataset de po√®mes simples
poems = [
    "Roses are red, violets are blue,",
    "The sky is vast, the ocean deep,",
    "Stars twinkle bright in the night sky,",
    "Rivers flow gently to the sea,",
    "Mountains stand tall against the wind,"
]

# Fine-tuning avec des donn√©es de po√©sie
# M√™me approche que pr√©c√©demment mais avec un style diff√©rent

# Test de g√©n√©ration de po√©sie
def generate_poem(prompt, model, tokenizer):
    model.eval()
    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)

    with torch.no_grad():
        output = model.generate(
            input_ids,
            max_length=50,
            temperature=0.8,
            num_return_sequences=1,
            pad_token_id=tokenizer.eos_token_id
        )

    return tokenizer.decode(output[0], skip_special_tokens=True)

# Exemples de g√©n√©ration
poem_prompts = ["The moon shines", "Love is like", "Time flows"]
for prompt in poem_prompts:
    poem = generate_poem(prompt, model, tokenizer)
    print(f"\\nPo√®me g√©n√©r√©:\\n{poem}")`
        }
      ]
    },
    {
      id: 'image-generation',
      title: 'G√©n√©ration d\'images avec l\'IA',
      content: `
        <div class="course-section">
          <h3>DALL¬∑E et la g√©n√©ration d\'images</h3>
          <p>DALL¬∑E est un mod√®le d\'IA d√©velopp√© par OpenAI capable de g√©n√©rer des images √† partir de descriptions textuelles. Il combine les capacit√©s de GPT pour comprendre le langage naturel avec celles d'un mod√®le de g√©n√©ration d'images.</p>

          <h4>Fonctionnement de DALL¬∑E :</h4>
          <ol>
            <li><strong>Encodage du texte :</strong> Le prompt textuel est transform√© en embedding</li>
            <li><strong>G√©n√©ration d'image :</strong> Un mod√®le de diffusion g√©n√®re l'image</li>
            <li><strong>Affinement :</strong> It√©rations pour am√©liorer la qualit√©</li>
            <li><strong>Variation :</strong> Possibilit√© de g√©n√©rer des variantes</li>
          </ol>

          <h3>Mod√®les de diffusion</h3>
          <p>Les mod√®les de diffusion sont l'approche dominante pour la g√©n√©ration d'images r√©alistes :</p>
          <ul>
            <li><strong>Forward process :</strong> Ajout progressif de bruit √† une image</li>
            <li><strong>Reverse process :</strong> Apprentissage √† retirer le bruit</li>
            <li><strong>Stable Diffusion :</strong> Mod√®le open-source populaire</li>
          </ul>

          <h3>Techniques de prompt engineering pour les images</h3>
          <ul>
            <li><strong>D√©tail descriptif :</strong> Plus le prompt est pr√©cis, mieux c'est</li>
            <li><strong>Style artistique :</strong> Sp√©cifier le style (peinture √† l'huile, photo r√©aliste)</li>
            <li><strong>Composition :</strong> Indiquer la disposition des √©l√©ments</li>
            <li><strong>Couleurs et √©clairage :</strong> Contr√¥ler l'ambiance visuelle</li>
          </ul>

          <div style="background-color: #fff3cd; padding: 15px; border-radius: 8px; border-left: 4px solid #ffc107; margin: 20px 0;">
            <h5 style="color: #856404; margin-top: 0;">üé® Conseils pour des prompts efficaces</h5>
            <ul>
              <li>Utilisez des adjectifs descriptifs</li>
              <li>Sp√©cifiez le medium artistique</li>
              <li>Indiquez la composition souhait√©e</li>
              <li>Ajoutez des d√©tails sur l'√©clairage</li>
            </ul>
          </div>
        </div>
      `,
      order: 3,
      estimatedTime: '3h',
      codeExamples: [
        {
          title: 'G√©n√©ration d\'images avec Stable Diffusion',
          description: 'Utilisation de Stable Diffusion via l\'API Hugging Face pour g√©n√©rer des images',
          code: `import requests
import json
from PIL import Image
import io
import matplotlib.pyplot as plt

# Configuration de l'API Hugging Face (n√©cessite un token)
API_URL = "https://api-inference.huggingface.co/models/CompVis/stable-diffusion-v1-4"
HEADERS = {"Authorization": f"Bearer {'YOUR_HF_TOKEN'}"}

def generate_image(prompt, negative_prompt="", width=512, height=512):
    """
    G√©n√®re une image √† partir d'un prompt textuel

    Args:
        prompt: Description de l'image souhait√©e
        negative_prompt: Ce qu'il faut √©viter dans l'image
        width, height: Dimensions de l'image
    """
    payload = {
        "inputs": prompt,
        "parameters": {
            "negative_prompt": negative_prompt,
            "width": width,
            "height": height,
            "num_inference_steps": 50,
            "guidance_scale": 7.5
        },
        "options": {"wait_for_model": True}
    }

    response = requests.post(API_URL, headers=HEADERS, json=payload)

    if response.status_code == 200:
        image = Image.open(io.BytesIO(response.content))
        return image
    else:
        print(f"Erreur API: {response.status_code}")
        print(response.text)
        return None

# Fonction pour afficher les images
def display_images(image_dict, cols=2):
    """Affiche plusieurs images g√©n√©r√©es"""
    rows = (len(image_dict) + cols - 1) // cols

    fig, axes = plt.subplots(rows, cols, figsize=(12, 8))

    if rows == 1:
        axes = axes.reshape(1, -1)
    elif cols == 1:
        axes = axes.reshape(-1, 1)

    for i, (title, img) in enumerate(image_dict.items()):
        row, col = i // cols, i % cols

        if img is not None:
            axes[row, col].imshow(img)
            axes[row, col].set_title(title, fontsize=10)
            axes[row, col].axis('off')
        else:
            axes[row, col].text(0.5, 0.5, f"Erreur g√©n√©ration\\n{title}",
                              ha='center', va='center', transform=axes[row, col].transAxes)

    plt.tight_layout()
    plt.show()

# Tests de g√©n√©ration d'images
print("üé® G√©n√©ration d'images avec Stable Diffusion...")

test_prompts = [
    "Un chat robotique dans un jardin futuriste, style cyberpunk, d√©tails haute r√©solution",
    "Portrait d'un scientifique IA dans un laboratoire high-tech, √©clairage dramatique",
    "Paysage urbain nocturne avec des tours lumineuses, style artistique num√©rique"
]

generated_images = {}

for i, prompt in enumerate(test_prompts, 1):
    print(f"\\nüñºÔ∏è G√©n√©ration {i}/3: {prompt[:50]}...")
    image = generate_image(prompt)
    generated_images[f"Image {i}"] = image

# Affichage des r√©sultats
print("\\nüì∏ Affichage des images g√©n√©r√©es:")
display_images(generated_images)

# Test avec des prompts plus cr√©atifs
print("\\nüé≠ Test avec diff√©rents styles artistiques:")

style_prompts = [
    "Un dragon m√©di√©val volant au-dessus d'un ch√¢teau, style peinture √† l'huile classique",
    "Portrait abstrait d'une femme, style cubiste Picasso, couleurs vives",
    "Paysage marin avec des vagues g√©antes, style impressionniste Monet"
]

style_images = {}
for i, prompt in enumerate(style_prompts, 1):
    print(f"\\nüé® Style {i}: {prompt[:50]}...")
    image = generate_image(prompt)
    style_images[f"Style {i}"] = image

display_images(style_images)

# Comparaison avec et sans prompt n√©gatif
print("\\n‚öñÔ∏è Test avec prompt n√©gatif:")

test_image = generate_image(
    prompt="Un chevalier en armure brillante dans une for√™t enchant√©e",
    negative_prompt="flou, d√©form√©, couleurs ternes, qualit√© m√©diocre"
)

comparison = {
    "Avec prompt n√©gatif": test_image,
    "Sans prompt n√©gatif": generate_image("Un chevalier en armure brillante dans une for√™t enchant√©e")
}

display_images(comparison, cols=1)`,
          language: 'python',
          explanation: 'Ce code montre comment utiliser l\'API Hugging Face pour g√©n√©rer des images avec Stable Diffusion en contr√¥lant la qualit√© et le style.'
        }
      ],
      exercises: [
        {
          id: 'ex-image-prompts',
          title: 'Ma√Ætrise des prompts pour les images',
          description: 'Exp√©rimentez diff√©rents types de prompts pour am√©liorer la qualit√© des images g√©n√©r√©es.',
          difficulty: 'moyen',
          solution: `# Strat√©gies de prompt engineering pour les images

strategies = [
    {
        "nom": "Basique",
        "prompt": "Un chat dans un jardin"
    },
    {
        "nom": "Descriptif",
        "prompt": "Un chat siamois aux yeux bleus, assis gracieusement dans un jardin japonais zen, fleurs de cerisier en arri√®re-plan, style photographie professionnelle, √©clairage naturel doux"
    },
    {
        "nom": "Artistique",
        "prompt": "Un chat mystique aux pouvoirs magiques, style fantasy art, couleurs vibrantes, d√©tails complexes, inspir√© de Studio Ghibli, haute qualit√© artistique"
    },
    {
        "nom": "Technique",
        "prompt": "Chat photographi√© en macro, d√©tails du pelage visible, profondeur de champ faible, arri√®re-plan flou, √©clairage studio professionnel, r√©solution 8K"
    }
]

print("üñºÔ∏è Comparaison des strat√©gies de prompting:")
for strategy in strategies:
    print(f"\\n--- {strategy['nom']} ---")
    print(f"Prompt: {strategy['prompt']}")
    # Note: Dans un environnement r√©el, vous g√©n√©reriez l'image ici
    print("G√©n√©ration d'image... (simul√©)")

print("\\nüìö Le√ßon: Plus le prompt est d√©taill√© et sp√©cifique, meilleure est l'image g√©n√©r√©e!")`
        }
      ]
    },
    {
      id: 'audio-generation',
      title: 'G√©n√©ration audio et synth√®se vocale',
      content: `
        <div class="course-section">
          <h3>Text-to-Speech (TTS) : de texte √† parole</h3>
          <p>La synth√®se vocale transforme le texte √©crit en parole naturelle. Les mod√®les modernes produisent une voix tr√®s r√©aliste avec l'intonation, le rythme et les √©motions appropri√©s.</p>

          <h4>Applications du TTS :</h4>
          <ul>
            <li><strong>Accessibilit√© :</strong> Aide aux personnes malvoyantes</li>
            <li><strong>Assistants virtuels :</strong> Siri, Alexa, Google Assistant</li>
            <li><strong>Audiolivres :</strong> Conversion automatique de texte en audio</li>
            <li><strong>√âducation :</strong> Support d'apprentissage personnalis√©</li>
          </ul>

          <h3>Mod√®les de synth√®se vocale avanc√©s</h3>
          <h4>WaveNet</h4>
          <p>D√©velopp√© par DeepMind, g√©n√®re de l'audio en pr√©disant les formes d'onde directement.</p>

          <h4>Tacotron</h4>
          <p>Combine un mod√®le s√©quence-√†-s√©quence avec un vocodeur pour produire une parole naturelle.</p>

          <h4>VALL-E</h4>
          <p>Mod√®le Microsoft capable de reproduire n'importe quelle voix avec seulement 3 secondes d'√©chantillon.</p>

          <h3>G√©n√©ration musicale avec l'IA</h3>
          <p>Les mod√®les comme MusicGen ou MuseNet peuvent composer de la musique originale dans diff√©rents styles.</p>

          <h4>Applications cr√©atives :</h4>
          <ul>
            <li><strong>Composition automatique :</strong> Cr√©ation de m√©lodies et harmonies</li>
            <li><strong>Accompagnement musical :</strong> G√©n√©ration de backing tracks</li>
            <li><strong>Remix et variation :</strong> Transformation de musique existante</li>
          </ul>
        </div>
      `,
      order: 4,
      estimatedTime: '2h 30min',
      codeExamples: [
        {
          title: 'Synth√®se vocale avec Tortoise TTS',
          description: 'G√©n√©ration de parole √† partir de texte avec contr√¥le de la voix et des √©motions',
          code: `import torch
import torchaudio
import IPython.display as ipd
import numpy as np

# Note: Installation requise: pip install tortoise-tts
try:
    from tortoise.api import TextToSpeech
except ImportError:
    print("Installation de Tortoise TTS n√©cessaire:")
    print("pip install tortoise-tts")
    print("Ou utilisez une alternative comme pyttsx3 pour ce d√©mo")

# Alternative avec pyttsx3 (plus simple √† installer)
import pyttsx3

def text_to_speech_simple(text, voice_id=0, rate=150):
    """
    Synth√®se vocale simple avec pyttsx3
    """
    engine = pyttsx3.init()

    # Configuration de la voix
    voices = engine.getProperty('voices')
    if voice_id < len(voices):
        engine.setProperty('voice', voices[voice_id].id)

    engine.setProperty('rate', rate)

    # Sauvegarde en fichier audio
    output_file = "generated_speech.wav"
    engine.save_to_file(text, output_file)
    engine.runAndWait()

    return output_file

# Tests de synth√®se vocale
texts = [
    "Bonjour et bienvenue dans ce cours sur l'intelligence artificielle g√©n√©rative.",
    "L'IA peut cr√©er du texte, des images, et m√™me de la musique de mani√®re autonome.",
    "Imaginez un monde o√π les ordinateurs composent des symphonies enti√®res.",
    "C'est exactement ce que nous allons explorer ensemble dans cette formation."
]

print("üé§ G√©n√©ration d'exemples audio...")

for i, text in enumerate(texts, 1):
    print(f"\\nüìù Texte {i}: {text[:50]}...")
    audio_file = text_to_speech_simple(text, rate=180)
    print(f"‚úÖ Audio sauvegard√©: {audio_file}")

# D√©monstration de diff√©rentes voix et vitesses
print("\\nüé≠ Variations de style:")

variations = [
    {"text": "Bonjour le monde", "rate": 120, "name": "Lente et pos√©e"},
    {"text": "Bonjour le monde", "rate": 200, "name": "Rapide et dynamique"},
    {"text": "Bonjour le monde !", "rate": 160, "name": "Enthousiaste"}
]

for var in variations:
    audio_file = text_to_speech_simple(var["text"], rate=var["rate"])
    print(f"{var['name']}: {audio_file}")

# G√©n√©ration de dialogues
print("\\nüí¨ G√©n√©ration de dialogue:")

dialogue = [
    "Bonjour, je suis votre assistant IA personnel.",
    "Comment puis-je vous aider aujourd'hui ?",
    "Je peux r√©pondre √† vos questions, g√©n√©rer du texte, ou m√™me cr√©er des images.",
    "Quelle t√¢che souhaitez-vous que j'accomplisse ?"
]

for line in dialogue:
    audio_file = text_to_speech_simple(line, rate=170)
    print(f"Assistant: {line[:40]}... ‚Üí {audio_file}")

print("\\nüéµ Tous les fichiers audio ont √©t√© g√©n√©r√©s avec succ√®s!")
print("Vous pouvez les √©couter pour entendre les diff√©rences de style et de d√©bit.")`,
          language: 'python',
          explanation: 'Ce code montre comment utiliser la synth√®se vocale pour transformer du texte en audio parl√© avec diff√©rents styles et d√©bits.'
        }
      ],
      exercises: [
        {
          id: 'ex-tts-story',
          title: 'Narration d\'histoire avec TTS',
          description: 'Cr√©ez un petit r√©cit et g√©n√©rez son √©quivalent audio avec diff√©rentes voix.',
          difficulty: 'facile',
          solution: `# Histoire √† narrer
story = """
Chapitre 1: La d√©couverte

Dans un petit village nich√© au c≈ìur des montagnes,
vivait un jeune inventeur nomm√© Alex.
Passionn√© par la science et la technologie,
il passait ses journ√©es dans son atelier,
entour√© d'engrenages, de circuits √©lectroniques,
et de r√™ves d'innovation.

Un jour, en explorant les greniers de sa maison familiale,
il d√©couvrit un ancien manuscrit poussi√©reux.
Les pages jaunies contenaient des formules math√©matiques complexes
et des sch√©mas d'appareils √©tranges.

Intrigu√©, Alex commen√ßa √† d√©crypter le document...
"""

# G√©n√©ration de l'audio de l'histoire
print("üìñ G√©n√©ration de la narration...")
audio_file = text_to_speech_simple(story, rate=160)
print(f"‚úÖ Histoire narr√©e sauvegard√©e: {audio_file}")

# Variantes avec diff√©rents styles
styles = [
    {"name": "Narrateur myst√®re", "rate": 140},
    {"name": "Narrateur dynamique", "rate": 180},
    {"name": "Narrateur solennel", "rate": 120}
]

for style in styles:
    audio_file = text_to_speech_simple(story, rate=style["rate"])
    print(f"{style['name']}: {audio_file}")`
        }
      ]
    }
  ],
  finalProject: {
    title: 'Application IA G√©n√©rative Compl√®te',
    description: 'D√©veloppez une application web qui combine g√©n√©ration de texte, d\'images et d\'audio pour cr√©er des exp√©riences multim√©dias uniques.',
    requirements: [
      'Interface web moderne avec sections pour chaque type de g√©n√©ration',
      'G√©n√©ration de texte avec GPT (prompt engineering avanc√©)',
      'G√©n√©ration d\'images avec Stable Diffusion (int√©gration API)',
      'Synth√®se vocale avec contr√¥le des voix et √©motions',
      'Fonctionnalit√© de combinaison : texte ‚Üí image ‚Üí audio',
      'Galerie des cr√©ations avec possibilit√© de sauvegarde',
      'Syst√®me de favoris et d\'historique des prompts',
      'Optimisation des performances (cache, file d\'attente)',
      'Interface responsive et accessible',
      'Documentation compl√®te de l\'API et du code'
    ],
    deliverables: [
      'Application web compl√®te et fonctionnelle',
      'Code source organis√© avec architecture modulaire',
      'API REST pour la g√©n√©ration de contenu',
      'Interface utilisateur intuitive avec pr√©visualisations',
      'Base de donn√©es pour sauvegarder les cr√©ations',
      'Rapport technique d√©taill√© (15-20 pages)',
      'Pr√©sentation vid√©o de d√©monstration',
      'Guide d\'utilisateur et tutoriels',
      'Tests automatis√©s et benchmarks de performance',
      'Plan de d√©ploiement et d\'h√©bergement'
    ]
  },
  resources: [
    {
      title: 'OpenAI API Documentation',
      type: 'documentation',
      url: 'https://platform.openai.com/docs'
    },
    {
      title: 'Hugging Face Diffusers',
      type: 'documentation',
      url: 'https://huggingface.co/docs/diffusers'
    },
    {
      title: 'Stable Diffusion WebUI',
      type: 'article',
      url: 'https://github.com/AUTOMATIC1111/stable-diffusion-webui'
    },
    {
      title: 'Tortoise TTS GitHub',
      type: 'article',
      url: 'https://github.com/neonbjb/tortoise-tts'
    },
    {
      title: 'The DALL¬∑E 2 Prompt Book',
      type: 'article',
      url: 'https://dalle2-prompt-book.com/'
    }
  ],
  tags: ['ia-generative', 'gpt', 'dall-e', 'stable-diffusion', 'text-to-speech', 'prompt-engineering', 'ai-art', 'multimodal']
};
