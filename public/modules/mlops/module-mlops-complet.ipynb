{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module MLOps - Formation Compl√®te\n",
    "\n",
    "## Plateforme IA-Solution RDC\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objectifs du module\n",
    "\n",
    "√Ä la fin de ce module, vous serez capable de :\n",
    "- Comprendre le cycle de vie complet d'un mod√®le ML\n",
    "- Utiliser Git pour versionner code et donn√©es\n",
    "- Containeriser des mod√®les avec Docker\n",
    "- Suivre les exp√©rimentations avec MLflow\n",
    "- D√©ployer des mod√®les via API REST\n",
    "- Appliquer le MLOps √† des cas concrets en RDC\n",
    "\n",
    "**Niveau :** Interm√©diaire/Avanc√©  \n",
    "**Pr√©requis :** Python, Machine Learning, Deep Learning  \n",
    "**Dur√©e :** 7 semaines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Table des mati√®res\n",
    "\n",
    "1. [Introduction au MLOps](#chapitre-1)\n",
    "2. [Cycle de vie d'un mod√®le IA](#chapitre-2)\n",
    "3. [Outils MLOps](#chapitre-3)\n",
    "4. [Exemple pratique complet](#chapitre-4)\n",
    "5. [Applications en RDC](#chapitre-5)\n",
    "6. [Projet final : API de pr√©diction](#chapitre-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Chapitre 1 : Introduction au MLOps <a id=\"chapitre-1\"></a>\n",
    "\n",
    "## 1.1 Qu'est-ce que le MLOps ?\n",
    "\n",
    "**MLOps** (Machine Learning Operations) est l'ensemble des pratiques qui permettent de **d√©ployer et maintenir des mod√®les ML en production** de mani√®re fiable, reproductible et √©volutive.\n",
    "\n",
    "### Analogie simple\n",
    "\n",
    "Imaginez que vous construisez une maison :\n",
    "- **Data Science** : Concevoir les plans de la maison (cr√©er le mod√®le)\n",
    "- **MLOps** : Construire la maison, l'entretenir, la r√©nover (d√©ployer et maintenir)\n",
    "\n",
    "### Diff√©rences Data Science vs MLOps\n",
    "\n",
    "| Aspect | Data Science | MLOps |\n",
    "|--------|--------------|-------|\n",
    "| **Objectif** | Cr√©er un mod√®le performant | D√©ployer et maintenir en production |\n",
    "| **Environnement** | Jupyter Notebook, local | Serveurs, cloud, production |\n",
    "| **Focus** | Pr√©cision, m√©triques | Fiabilit√©, scalabilit√©, monitoring |\n",
    "| **Outils** | Pandas, Scikit-learn | Docker, Kubernetes, CI/CD |\n",
    "| **Dur√©e** | Projet ponctuel | Maintenance continue |\n",
    "\n",
    "## 1.2 Pourquoi le MLOps est important ?\n",
    "\n",
    "### Probl√®mes sans MLOps\n",
    "\n",
    "1. **\"√áa marche sur mon ordinateur\"**\n",
    "   - Le mod√®le fonctionne en local mais pas en production\n",
    "   - Diff√©rences d'environnement (versions, d√©pendances)\n",
    "\n",
    "2. **Mod√®les non reproductibles**\n",
    "   - Impossible de recr√©er les m√™mes r√©sultats\n",
    "   - Perte de code ou de donn√©es\n",
    "\n",
    "3. **D√©gradation des performances**\n",
    "   - Le mod√®le devient moins pr√©cis avec le temps\n",
    "   - Pas de monitoring\n",
    "\n",
    "4. **D√©ploiement lent et risqu√©**\n",
    "   - Processus manuel et long\n",
    "   - Risque d'erreurs\n",
    "\n",
    "### Solutions avec MLOps\n",
    "\n",
    "1. **Containerisation** (Docker)\n",
    "   - Environnement identique partout\n",
    "   - \"√áa marche partout\"\n",
    "\n",
    "2. **Versioning** (Git, DVC)\n",
    "   - Code et donn√©es versionn√©s\n",
    "   - Reproductibilit√© garantie\n",
    "\n",
    "3. **Monitoring**\n",
    "   - Suivi des performances\n",
    "   - Alertes automatiques\n",
    "\n",
    "4. **CI/CD**\n",
    "   - D√©ploiement automatis√©\n",
    "   - Tests automatiques\n",
    "\n",
    "## 1.3 Applications en RDC\n",
    "\n",
    "### üè• **Sant√©**\n",
    "- D√©ploiement de mod√®les de diagnostic dans plusieurs h√¥pitaux\n",
    "- Monitoring de la pr√©cision en temps r√©el\n",
    "- Mise √† jour automatique des mod√®les\n",
    "\n",
    "### üåæ **Agriculture**\n",
    "- API de pr√©diction de rendement accessible aux agriculteurs\n",
    "- Mod√®les adapt√©s √† chaque r√©gion\n",
    "- Suivi de la qualit√© des pr√©dictions\n",
    "\n",
    "### ‚ö° **√ânergie**\n",
    "- Optimisation de la consommation √©lectrique\n",
    "- Pr√©diction de la demande\n",
    "- D√©tection d'anomalies\n",
    "\n",
    "### üí∞ **Finance**\n",
    "- D√©tection de fraudes en temps r√©el\n",
    "- Mod√®les mis √† jour quotidiennement\n",
    "- Haute disponibilit√© (99.9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des biblioth√®ques n√©cessaires\n",
    "!pip install scikit-learn pandas numpy matplotlib mlflow fastapi uvicorn -q\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques install√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Imports termin√©s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Chapitre 2 : Cycle de vie d'un mod√®le IA <a id=\"chapitre-2\"></a>\n",
    "\n",
    "## 2.1 Les √©tapes du cycle de vie\n",
    "\n",
    "```\n",
    "1. Collecte de donn√©es\n",
    "   ‚Üì\n",
    "2. Pr√©paration des donn√©es\n",
    "   ‚Üì\n",
    "3. Entra√Ænement du mod√®le\n",
    "   ‚Üì\n",
    "4. √âvaluation\n",
    "   ‚Üì\n",
    "5. D√©ploiement\n",
    "   ‚Üì\n",
    "6. Monitoring\n",
    "   ‚Üì\n",
    "7. R√©entra√Ænement (retour √† l'√©tape 1)\n",
    "```\n",
    "\n",
    "## 2.2 √âtape 1 : Collecte de donn√©es\n",
    "\n",
    "### Bonnes pratiques\n",
    "\n",
    "1. **Qualit√© > Quantit√©**\n",
    "   - Donn√©es propres et pertinentes\n",
    "   - √âviter les biais\n",
    "\n",
    "2. **Documentation**\n",
    "   - Source des donn√©es\n",
    "   - Date de collecte\n",
    "   - M√©thodologie\n",
    "\n",
    "3. **Versioning**\n",
    "   - Utiliser DVC (Data Version Control)\n",
    "   - Tracer les modifications\n",
    "\n",
    "## 2.3 √âtape 2 : Pr√©paration des donn√©es\n",
    "\n",
    "### T√¢ches principales\n",
    "\n",
    "1. **Nettoyage**\n",
    "   - G√©rer les valeurs manquantes\n",
    "   - Supprimer les doublons\n",
    "   - Corriger les erreurs\n",
    "\n",
    "2. **Transformation**\n",
    "   - Normalisation/Standardisation\n",
    "   - Encodage des variables cat√©gorielles\n",
    "   - Feature engineering\n",
    "\n",
    "3. **Split**\n",
    "   - Train/Validation/Test\n",
    "   - Stratification si n√©cessaire\n",
    "\n",
    "## 2.4 √âtape 3 : Entra√Ænement\n",
    "\n",
    "### Bonnes pratiques\n",
    "\n",
    "1. **Exp√©rimentation**\n",
    "   - Tester plusieurs algorithmes\n",
    "   - Optimiser les hyperparam√®tres\n",
    "   - Documenter chaque exp√©rience\n",
    "\n",
    "2. **Tracking**\n",
    "   - Utiliser MLflow\n",
    "   - Enregistrer m√©triques et param√®tres\n",
    "   - Sauvegarder les mod√®les\n",
    "\n",
    "## 2.5 √âtape 4 : √âvaluation\n",
    "\n",
    "### M√©triques importantes\n",
    "\n",
    "- **Classification** : Accuracy, Precision, Recall, F1-Score\n",
    "- **R√©gression** : MAE, MSE, RMSE, R¬≤\n",
    "- **M√©tiers** : Co√ªt des erreurs, temps de r√©ponse\n",
    "\n",
    "## 2.6 √âtape 5 : D√©ploiement\n",
    "\n",
    "### Options de d√©ploiement\n",
    "\n",
    "1. **API REST** (FastAPI, Flask)\n",
    "   - Accessible via HTTP\n",
    "   - Facile √† int√©grer\n",
    "\n",
    "2. **Batch** (Airflow, Cron)\n",
    "   - Pr√©dictions en masse\n",
    "   - Planifi√©es\n",
    "\n",
    "3. **Edge** (TensorFlow Lite, ONNX)\n",
    "   - Sur appareil mobile\n",
    "   - Hors ligne\n",
    "\n",
    "## 2.7 √âtape 6 : Monitoring\n",
    "\n",
    "### M√©triques √† surveiller\n",
    "\n",
    "1. **Performance du mod√®le**\n",
    "   - Pr√©cision en production\n",
    "   - Drift des donn√©es\n",
    "\n",
    "2. **Performance syst√®me**\n",
    "   - Temps de r√©ponse\n",
    "   - Utilisation CPU/RAM\n",
    "   - Disponibilit√©\n",
    "\n",
    "3. **M√©tiers**\n",
    "   - Impact business\n",
    "   - Satisfaction utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple complet : Cycle de vie d'un mod√®le de pr√©diction de paludisme\n",
    "\n",
    "# 1. Collecte de donn√©es (synth√©tiques pour l'exemple)\n",
    "print(\"üìä √âTAPE 1 : COLLECTE DE DONN√âES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Donn√©es : [Temp√©rature, Fatigue (0-10), Maux de t√™te (0-10), Frissons (0/1)]\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Cas positifs (paludisme)\n",
    "X_pos = np.random.randn(n_samples // 2, 4) * np.array([1, 1.5, 1.5, 0.3]) + np.array([39.5, 8, 8, 0.8])\n",
    "y_pos = np.ones(n_samples // 2)\n",
    "\n",
    "# Cas n√©gatifs (sain)\n",
    "X_neg = np.random.randn(n_samples // 2, 4) * np.array([0.5, 2, 2, 0.3]) + np.array([37, 3, 3, 0.2])\n",
    "y_neg = np.zeros(n_samples // 2)\n",
    "\n",
    "# Combiner\n",
    "X = np.vstack([X_pos, X_neg])\n",
    "y = np.hstack([y_pos, y_neg])\n",
    "\n",
    "# Cr√©er DataFrame\n",
    "df = pd.DataFrame(X, columns=['Temperature', 'Fatigue', 'Maux_tete', 'Frissons'])\n",
    "df['Paludisme'] = y\n",
    "\n",
    "print(f\"Donn√©es collect√©es : {len(df)} exemples\")\n",
    "print(f\"\\nAper√ßu des donn√©es :\")\n",
    "print(df.head())\n",
    "print(f\"\\nDistribution des classes :\")\n",
    "print(df['Paludisme'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pr√©paration des donn√©es\n",
    "print(\"\\nüîß √âTAPE 2 : PR√âPARATION DES DONN√âES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# S√©parer features et target\n",
    "X = df.drop('Paludisme', axis=1)\n",
    "y = df['Paludisme']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set : {len(X_train)} exemples\")\n",
    "print(f\"Test set : {len(X_test)} exemples\")\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Donn√©es normalis√©es\")\n",
    "print(f\"Moyenne : {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"√âcart-type : {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Entra√Ænement du mod√®le\n",
    "print(\"\\nüéì √âTAPE 3 : ENTRA√éNEMENT DU MOD√àLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cr√©er et entra√Æner le mod√®le\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"‚úÖ Mod√®le entra√Æn√© : Random Forest (100 arbres)\")\n",
    "\n",
    "# Importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportance des features :\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. √âvaluation\n",
    "print(\"\\nüìà √âTAPE 4 : √âVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "# M√©triques\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Pr√©cision Train : {train_acc * 100:.2f}%\")\n",
    "print(f\"Pr√©cision Test : {test_acc * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nRapport de classification (Test) :\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Sain', 'Paludisme']))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"\\nMatrice de confusion :\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Sauvegarde du mod√®le (pr√©paration au d√©ploiement)\n",
    "print(\"\\nüíæ √âTAPE 5 : SAUVEGARDE DU MOD√àLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cr√©er un dossier pour les mod√®les\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "model_path = 'models/paludisme_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"‚úÖ Mod√®le sauvegard√© : {model_path}\")\n",
    "\n",
    "# Sauvegarder le scaler\n",
    "scaler_path = 'models/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úÖ Scaler sauvegard√© : {scaler_path}\")\n",
    "\n",
    "# Sauvegarder les m√©tadonn√©es\n",
    "metadata = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'n_estimators': 100,\n",
    "    'features': list(X.columns),\n",
    "    'train_accuracy': float(train_acc),\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'n_train_samples': len(X_train),\n",
    "    'n_test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "metadata_path = 'models/metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"‚úÖ M√©tadonn√©es sauvegard√©es : {metadata_path}\")\n",
    "\n",
    "print(\"\\nüì¶ Mod√®le pr√™t pour le d√©ploiement !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Exercice 1 : Cycle de vie complet\n",
    "\n",
    "Cr√©ez un mod√®le de pr√©diction de rendement agricole :\n",
    "1. G√©n√©rez des donn√©es synth√©tiques (pluie, engrais, temp√©rature ‚Üí rendement)\n",
    "2. Pr√©parez les donn√©es\n",
    "3. Entra√Ænez un mod√®le de r√©gression\n",
    "4. √âvaluez avec MAE et R¬≤\n",
    "5. Sauvegardez le mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 1 : √Ä vous de jouer !\n",
    "\n",
    "# TODO: Cr√©ez votre mod√®le de pr√©diction de rendement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Chapitre 3 : Outils MLOps <a id=\"chapitre-3\"></a>\n",
    "\n",
    "## 3.1 Git et GitHub\n",
    "\n",
    "**Git** est un syst√®me de contr√¥le de version qui permet de :\n",
    "- Suivre les modifications du code\n",
    "- Collaborer avec d'autres d√©veloppeurs\n",
    "- Revenir √† des versions ant√©rieures\n",
    "\n",
    "### Commandes essentielles\n",
    "\n",
    "```bash\n",
    "# Initialiser un d√©p√¥t\n",
    "git init\n",
    "\n",
    "# Ajouter des fichiers\n",
    "git add .\n",
    "\n",
    "# Commit\n",
    "git commit -m \"Message descriptif\"\n",
    "\n",
    "# Pousser vers GitHub\n",
    "git push origin main\n",
    "\n",
    "# Cloner un d√©p√¥t\n",
    "git clone https://github.com/user/repo.git\n",
    "```\n",
    "\n",
    "### Structure d'un projet ML\n",
    "\n",
    "```\n",
    "projet-ml/\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/           # Donn√©es brutes\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ processed/     # Donn√©es pr√©par√©es\n",
    "‚îú‚îÄ‚îÄ notebooks/         # Jupyter notebooks\n",
    "‚îú‚îÄ‚îÄ src/              # Code source\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ data/         # Scripts de pr√©paration\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ models/       # D√©finition des mod√®les\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ api/          # API de d√©ploiement\n",
    "‚îú‚îÄ‚îÄ models/           # Mod√®les sauvegard√©s\n",
    "‚îú‚îÄ‚îÄ tests/            # Tests unitaires\n",
    "‚îú‚îÄ‚îÄ requirements.txt  # D√©pendances\n",
    "‚îú‚îÄ‚îÄ Dockerfile        # Configuration Docker\n",
    "‚îî‚îÄ‚îÄ README.md         # Documentation\n",
    "```\n",
    "\n",
    "## 3.2 Docker\n",
    "\n",
    "**Docker** permet de cr√©er des **containers** : des environnements isol√©s et reproductibles.\n",
    "\n",
    "### Avantages\n",
    "\n",
    "- ‚úÖ M√™me environnement partout (dev, test, prod)\n",
    "- ‚úÖ Isolation des d√©pendances\n",
    "- ‚úÖ D√©ploiement facile\n",
    "- ‚úÖ Scalabilit√©\n",
    "\n",
    "### Dockerfile exemple\n",
    "\n",
    "```dockerfile\n",
    "# Image de base\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# R√©pertoire de travail\n",
    "WORKDIR /app\n",
    "\n",
    "# Copier les d√©pendances\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copier le code\n",
    "COPY . .\n",
    "\n",
    "# Exposer le port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Commande de d√©marrage\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "### Commandes Docker\n",
    "\n",
    "```bash\n",
    "# Construire une image\n",
    "docker build -t mon-modele-ml .\n",
    "\n",
    "# Lancer un container\n",
    "docker run -p 8000:8000 mon-modele-ml\n",
    "\n",
    "# Lister les containers\n",
    "docker ps\n",
    "\n",
    "# Arr√™ter un container\n",
    "docker stop <container_id>\n",
    "```\n",
    "\n",
    "## 3.3 MLflow\n",
    "\n",
    "**MLflow** est une plateforme pour g√©rer le cycle de vie ML :\n",
    "- Tracking des exp√©rimentations\n",
    "- Gestion des mod√®les\n",
    "- D√©ploiement\n",
    "\n",
    "### Composants\n",
    "\n",
    "1. **MLflow Tracking** : Enregistrer m√©triques et param√®tres\n",
    "2. **MLflow Projects** : Packager le code\n",
    "3. **MLflow Models** : Format standard pour les mod√®les\n",
    "4. **MLflow Registry** : Gestion centralis√©e des mod√®les\n",
    "\n",
    "## 3.4 CI/CD\n",
    "\n",
    "**CI/CD** (Continuous Integration / Continuous Deployment) automatise le processus de d√©ploiement.\n",
    "\n",
    "### Pipeline CI/CD typique\n",
    "\n",
    "```\n",
    "1. Push du code (Git)\n",
    "   ‚Üì\n",
    "2. Tests automatiques\n",
    "   ‚Üì\n",
    "3. Build de l'image Docker\n",
    "   ‚Üì\n",
    "4. D√©ploiement en staging\n",
    "   ‚Üì\n",
    "5. Tests d'int√©gration\n",
    "   ‚Üì\n",
    "6. D√©ploiement en production\n",
    "```\n",
    "\n",
    "### Outils\n",
    "\n",
    "- **GitHub Actions** : Int√©gr√© √† GitHub\n",
    "- **GitLab CI** : Int√©gr√© √† GitLab\n",
    "- **Jenkins** : Open-source, tr√®s flexible\n",
    "- **CircleCI** : Cloud, facile √† utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de MLflow\n",
    "!pip install mlflow -q\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : Tracking avec MLflow\n",
    "\n",
    "print(\"üìä TRACKING AVEC MLFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# D√©finir l'exp√©rience\n",
    "mlflow.set_experiment(\"Paludisme_Detection\")\n",
    "\n",
    "# D√©marrer un run\n",
    "with mlflow.start_run(run_name=\"RandomForest_v1\"):\n",
    "    \n",
    "    # Enregistrer les param√®tres\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    \n",
    "    # Entra√Æner le mod√®le\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = model_rf.predict(X_test_scaled)\n",
    "    \n",
    "    # Enregistrer les m√©triques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"n_train_samples\", len(X_train))\n",
    "    mlflow.log_metric(\"n_test_samples\", len(X_test))\n",
    "    \n",
    "    # Enregistrer le mod√®le\n",
    "    mlflow.sklearn.log_model(model_rf, \"model\")\n",
    "    \n",
    "    print(f\"‚úÖ Run enregistr√© avec pr√©cision : {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nüí° Pour voir l'interface MLflow :\")\n",
    "print(\"   mlflow ui\")\n",
    "print(\"   Puis ouvrir : http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer plusieurs mod√®les avec MLflow\n",
    "\n",
    "print(\"\\nüî¨ COMPARAISON DE MOD√àLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "models_to_test = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42)),\n",
    "    (\"Random Forest (50)\", RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    (\"Random Forest (100)\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    (\"Random Forest (200)\", RandomForestClassifier(n_estimators=200, random_state=42)),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models_to_test:\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Entra√Æner\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Pr√©dire\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # M√©triques\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Log\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        results.append({'Model': name, 'Accuracy': accuracy})\n",
    "        print(f\"{name:<25} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Afficher le meilleur mod√®le\n",
    "results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\nüèÜ Meilleur mod√®le :\")\n",
    "print(results_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Exercice 2 : Tracking avec MLflow\n",
    "\n",
    "Utilisez MLflow pour comparer 3 mod√®les de r√©gression :\n",
    "1. Linear Regression\n",
    "2. Ridge Regression\n",
    "3. Random Forest Regressor\n",
    "\n",
    "Enregistrez les m√©triques MAE et R¬≤ pour chaque mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 2 : √Ä vous de jouer !\n",
    "\n",
    "# TODO: Comparez 3 mod√®les de r√©gression avec MLflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Chapitre 4 : Exemple pratique complet <a id=\"chapitre-4\"></a>\n",
    "\n",
    "## 4.1 Cr√©er une API REST avec FastAPI\n",
    "\n",
    "**FastAPI** est un framework moderne pour cr√©er des APIs en Python.\n",
    "\n",
    "### Avantages\n",
    "\n",
    "- ‚úÖ Tr√®s rapide (performance)\n",
    "- ‚úÖ Documentation automatique\n",
    "- ‚úÖ Validation des donn√©es\n",
    "- ‚úÖ Facile √† utiliser\n",
    "\n",
    "### Structure d'une API ML\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "\n",
    "# Charger le mod√®le\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Cr√©er l'app\n",
    "app = FastAPI()\n",
    "\n",
    "# D√©finir le sch√©ma d'entr√©e\n",
    "class PredictionInput(BaseModel):\n",
    "    feature1: float\n",
    "    feature2: float\n",
    "\n",
    "# Endpoint de pr√©diction\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: PredictionInput):\n",
    "    # Faire la pr√©diction\n",
    "    prediction = model.predict([[data.feature1, data.feature2]])\n",
    "    return {\"prediction\": int(prediction[0])}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un fichier API pour notre mod√®le de paludisme\n",
    "\n",
    "api_code = '''\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Charger le mod√®le et le scaler\n",
    "model = joblib.load('models/paludisme_model.pkl')\n",
    "scaler = joblib.load('models/scaler.pkl')\n",
    "\n",
    "# Cr√©er l'application\n",
    "app = FastAPI(\n",
    "    title=\"API de D√©tection du Paludisme\",\n",
    "    description=\"API pour pr√©dire si un patient a le paludisme\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Sch√©ma d'entr√©e\n",
    "class PatientData(BaseModel):\n",
    "    temperature: float\n",
    "    fatigue: float  # 0-10\n",
    "    maux_tete: float  # 0-10\n",
    "    frissons: float  # 0-1\n",
    "    \n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"temperature\": 39.5,\n",
    "                \"fatigue\": 8.0,\n",
    "                \"maux_tete\": 9.0,\n",
    "                \"frissons\": 1.0\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Sch√©ma de sortie\n",
    "class PredictionResponse(BaseModel):\n",
    "    prediction: int  # 0 = Sain, 1 = Paludisme\n",
    "    probability: float\n",
    "    message: str\n",
    "\n",
    "# Endpoint racine\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\n",
    "        \"message\": \"API de D√©tection du Paludisme - RDC\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"endpoints\": {\n",
    "            \"/predict\": \"POST - Faire une pr√©diction\",\n",
    "            \"/health\": \"GET - V√©rifier l'√©tat de l'API\",\n",
    "            \"/docs\": \"GET - Documentation interactive\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Endpoint de sant√©\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"healthy\", \"model_loaded\": True}\n",
    "\n",
    "# Endpoint de pr√©diction\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "def predict(data: PatientData):\n",
    "    # Pr√©parer les donn√©es\n",
    "    features = np.array([[\n",
    "        data.temperature,\n",
    "        data.fatigue,\n",
    "        data.maux_tete,\n",
    "        data.frissons\n",
    "    ]])\n",
    "    \n",
    "    # Normaliser\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Pr√©dire\n",
    "    prediction = model.predict(features_scaled)[0]\n",
    "    probability = model.predict_proba(features_scaled)[0][1]\n",
    "    \n",
    "    # Message\n",
    "    if prediction == 1:\n",
    "        message = f\"‚ö†Ô∏è Risque de paludisme √©lev√© ({probability*100:.1f}%). Consultez un m√©decin.\"\n",
    "    else:\n",
    "        message = f\"‚úÖ Risque de paludisme faible ({probability*100:.1f}%).\"\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": int(prediction),\n",
    "        \"probability\": float(probability),\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "'''\n",
    "\n",
    "# Sauvegarder le fichier\n",
    "with open('main.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(api_code)\n",
    "\n",
    "print(\"‚úÖ Fichier API cr√©√© : main.py\")\n",
    "print(\"\\nüìù Pour lancer l'API :\")\n",
    "print(\"   uvicorn main:app --reload\")\n",
    "print(\"\\nüìö Documentation interactive :\")\n",
    "print(\"   http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un Dockerfile\n",
    "\n",
    "dockerfile_content = '''# Image de base\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# M√©tadonn√©es\n",
    "LABEL maintainer=\"IA-Solution RDC\"\n",
    "LABEL description=\"API de d√©tection du paludisme\"\n",
    "\n",
    "# R√©pertoire de travail\n",
    "WORKDIR /app\n",
    "\n",
    "# Copier les requirements\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Installer les d√©pendances\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copier le code et les mod√®les\n",
    "COPY main.py .\n",
    "COPY models/ models/\n",
    "\n",
    "# Exposer le port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Commande de d√©marrage\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "'''\n",
    "\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "\n",
    "print(\"‚úÖ Dockerfile cr√©√©\")\n",
    "\n",
    "# Cr√©er requirements.txt\n",
    "requirements = '''fastapi==0.104.1\n",
    "uvicorn[standard]==0.24.0\n",
    "pydantic==2.5.0\n",
    "scikit-learn==1.3.2\n",
    "joblib==1.3.2\n",
    "numpy==1.24.3\n",
    "'''\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"‚úÖ requirements.txt cr√©√©\")\n",
    "\n",
    "print(\"\\nüê≥ Pour construire l'image Docker :\")\n",
    "print(\"   docker build -t paludisme-api .\")\n",
    "print(\"\\nüöÄ Pour lancer le container :\")\n",
    "print(\"   docker run -p 8000:8000 paludisme-api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Tester l'API\n",
    "\n",
    "### Avec curl\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://localhost:8000/predict\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"temperature\": 39.5, \"fatigue\": 8, \"maux_tete\": 9, \"frissons\": 1}'\n",
    "```\n",
    "\n",
    "### Avec Python\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "data = {\n",
    "    \"temperature\": 39.5,\n",
    "    \"fatigue\": 8.0,\n",
    "    \"maux_tete\": 9.0,\n",
    "    \"frissons\": 1.0\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/predict\", json=data)\n",
    "print(response.json())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler un appel API (si l'API est lanc√©e)\n",
    "\n",
    "import requests\n",
    "\n",
    "def test_api(base_url=\"http://localhost:8000\"):\n",
    "    \"\"\"Teste l'API de pr√©diction\"\"\"\n",
    "    \n",
    "    print(\"üß™ TEST DE L'API\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test 1 : Endpoint racine\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/\")\n",
    "        print(\"‚úÖ Endpoint racine : OK\")\n",
    "        print(response.json())\n",
    "    except:\n",
    "        print(\"‚ùå API non accessible. Lancez-la avec : uvicorn main:app\")\n",
    "        return\n",
    "    \n",
    "    # Test 2 : Health check\n",
    "    response = requests.get(f\"{base_url}/health\")\n",
    "    print(\"\\n‚úÖ Health check : OK\")\n",
    "    print(response.json())\n",
    "    \n",
    "    # Test 3 : Pr√©diction (cas positif)\n",
    "    data_positif = {\n",
    "        \"temperature\": 39.5,\n",
    "        \"fatigue\": 8.0,\n",
    "        \"maux_tete\": 9.0,\n",
    "        \"frissons\": 1.0\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{base_url}/predict\", json=data_positif)\n",
    "    print(\"\\n‚úÖ Pr√©diction (cas positif) :\")\n",
    "    print(response.json())\n",
    "    \n",
    "    # Test 4 : Pr√©diction (cas n√©gatif)\n",
    "    data_negatif = {\n",
    "        \"temperature\": 37.0,\n",
    "        \"fatigue\": 2.0,\n",
    "        \"maux_tete\": 1.0,\n",
    "        \"frissons\": 0.0\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{base_url}/predict\", json=data_negatif)\n",
    "    print(\"\\n‚úÖ Pr√©diction (cas n√©gatif) :\")\n",
    "    print(response.json())\n",
    "\n",
    "# D√©commenter pour tester (si l'API est lanc√©e)\n",
    "# test_api()\n",
    "\n",
    "print(\"\\nüí° Pour tester l'API :\")\n",
    "print(\"1. Lancez l'API : uvicorn main:app --reload\")\n",
    "print(\"2. D√©commentez et ex√©cutez : test_api()\")\n",
    "print(\"3. Ou visitez : http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Exercice 3 : Cr√©er votre API\n",
    "\n",
    "Cr√©ez une API REST pour votre mod√®le de pr√©diction de rendement agricole :\n",
    "1. D√©finissez le sch√©ma d'entr√©e (pluie, engrais, temp√©rature)\n",
    "2. Cr√©ez l'endpoint `/predict`\n",
    "3. Testez avec diff√©rentes valeurs\n",
    "4. Cr√©ez un Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 3 : √Ä vous de jouer !\n",
    "\n",
    "# TODO: Cr√©ez votre API de pr√©diction de rendement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Chapitre 5 : Applications en RDC <a id=\"chapitre-5\"></a>\n",
    "\n",
    "## 5.1 Sant√© : Suivi des mod√®les de diagnostic\n",
    "\n",
    "### Cas d'usage\n",
    "\n",
    "**Syst√®me de d√©tection du paludisme d√©ploy√© dans 10 h√¥pitaux**\n",
    "\n",
    "**Architecture :**\n",
    "```\n",
    "H√¥pitaux (10) ‚Üí API Centrale ‚Üí Base de donn√©es\n",
    "                     ‚Üì\n",
    "              Dashboard Monitoring\n",
    "```\n",
    "\n",
    "**M√©triques suivies :**\n",
    "- Pr√©cision par h√¥pital\n",
    "- Nombre de pr√©dictions/jour\n",
    "- Temps de r√©ponse\n",
    "- Taux de faux positifs/n√©gatifs\n",
    "\n",
    "**Alertes :**\n",
    "- Pr√©cision < 90% ‚Üí R√©entra√Ænement\n",
    "- Temps de r√©ponse > 2s ‚Üí Optimisation\n",
    "- API down ‚Üí Notification imm√©diate\n",
    "\n",
    "## 5.2 Agriculture : Pr√©diction de rendement\n",
    "\n",
    "### Cas d'usage\n",
    "\n",
    "**Application mobile pour agriculteurs**\n",
    "\n",
    "**Fonctionnalit√©s :**\n",
    "- Pr√©diction du rendement (manioc, ma√Øs)\n",
    "- Recommandations d'engrais\n",
    "- Alertes m√©t√©o\n",
    "\n",
    "**Pipeline MLOps :**\n",
    "1. Collecte de donn√©es (capteurs, satellites)\n",
    "2. R√©entra√Ænement mensuel\n",
    "3. A/B testing des nouveaux mod√®les\n",
    "4. D√©ploiement progressif\n",
    "\n",
    "## 5.3 √ânergie : Optimisation de la consommation\n",
    "\n",
    "### Cas d'usage\n",
    "\n",
    "**Pr√©diction de la demande √©lectrique √† Kinshasa**\n",
    "\n",
    "**Donn√©es :**\n",
    "- Historique de consommation\n",
    "- M√©t√©o\n",
    "- √âv√©nements (matchs, f√™tes)\n",
    "- Jour de la semaine\n",
    "\n",
    "**B√©n√©fices :**\n",
    "- R√©duction des coupures\n",
    "- Optimisation de la production\n",
    "- √âconomies de co√ªts\n",
    "\n",
    "**MLOps :**\n",
    "- R√©entra√Ænement quotidien\n",
    "- Pr√©dictions toutes les heures\n",
    "- Monitoring en temps r√©el\n",
    "- Alertes automatiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : Dashboard de monitoring simple\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Simuler des donn√©es de monitoring\n",
    "dates = pd.date_range(start='2025-01-01', end='2025-01-30', freq='D')\n",
    "monitoring_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'predictions': np.random.randint(50, 200, len(dates)),\n",
    "    'accuracy': np.random.uniform(0.85, 0.98, len(dates)),\n",
    "    'response_time_ms': np.random.uniform(50, 300, len(dates)),\n",
    "    'errors': np.random.randint(0, 5, len(dates))\n",
    "})\n",
    "\n",
    "print(\"üìä DASHBOARD DE MONITORING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nP√©riode : {dates[0].date()} √† {dates[-1].date()}\")\n",
    "print(f\"\\nStatistiques :\")\n",
    "print(f\"- Total pr√©dictions : {monitoring_data['predictions'].sum()}\")\n",
    "print(f\"- Pr√©cision moyenne : {monitoring_data['accuracy'].mean() * 100:.2f}%\")\n",
    "print(f\"- Temps de r√©ponse moyen : {monitoring_data['response_time_ms'].mean():.0f} ms\")\n",
    "print(f\"- Total erreurs : {monitoring_data['errors'].sum()}\")\n",
    "\n",
    "# Visualiser\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Pr√©dictions par jour\n",
    "axes[0, 0].plot(monitoring_data['date'], monitoring_data['predictions'], 'b-', linewidth=2)\n",
    "axes[0, 0].set_title('Pr√©dictions par jour', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Nombre')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Pr√©cision\n",
    "axes[0, 1].plot(monitoring_data['date'], monitoring_data['accuracy'] * 100, 'g-', linewidth=2)\n",
    "axes[0, 1].axhline(y=90, color='r', linestyle='--', label='Seuil minimum')\n",
    "axes[0, 1].set_title('Pr√©cision du mod√®le', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Pr√©cision (%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Temps de r√©ponse\n",
    "axes[1, 0].plot(monitoring_data['date'], monitoring_data['response_time_ms'], 'orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=200, color='r', linestyle='--', label='Seuil maximum')\n",
    "axes[1, 0].set_title('Temps de r√©ponse', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Temps (ms)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Erreurs\n",
    "axes[1, 1].bar(monitoring_data['date'], monitoring_data['errors'], color='red', alpha=0.6)\n",
    "axes[1, 1].set_title('Erreurs par jour', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Nombre')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Alertes\n",
    "print(\"\\nüö® ALERTES :\")\n",
    "low_accuracy = monitoring_data[monitoring_data['accuracy'] < 0.90]\n",
    "if len(low_accuracy) > 0:\n",
    "    print(f\"‚ö†Ô∏è Pr√©cision < 90% d√©tect√©e {len(low_accuracy)} fois\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucune alerte de pr√©cision\")\n",
    "\n",
    "slow_response = monitoring_data[monitoring_data['response_time_ms'] > 200]\n",
    "if len(slow_response) > 0:\n",
    "    print(f\"‚ö†Ô∏è Temps de r√©ponse > 200ms d√©tect√© {len(slow_response)} fois\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucune alerte de performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Exercice 4 : Monitoring\n",
    "\n",
    "Cr√©ez un syst√®me de monitoring pour votre mod√®le :\n",
    "1. Simulez des donn√©es de production (30 jours)\n",
    "2. Calculez les m√©triques cl√©s\n",
    "3. Cr√©ez des visualisations\n",
    "4. D√©finissez des seuils d'alerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 : √Ä vous de jouer !\n",
    "\n",
    "# TODO: Cr√©ez votre syst√®me de monitoring\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Chapitre 6 : Projet final <a id=\"chapitre-6\"></a>\n",
    "\n",
    "## üéØ Objectif du projet\n",
    "\n",
    "Cr√©er un **syst√®me MLOps complet** pour un mod√®le de pr√©diction m√©t√©o en RDC.\n",
    "\n",
    "## Sp√©cifications\n",
    "\n",
    "### 1. Mod√®le\n",
    "- Pr√©dire la pluie du lendemain (classification binaire)\n",
    "- Features : temp√©rature, humidit√©, pression, vent\n",
    "- Pr√©cision > 85%\n",
    "\n",
    "### 2. Versioning\n",
    "- Code versionn√© avec Git\n",
    "- Mod√®les track√©s avec MLflow\n",
    "\n",
    "### 3. API\n",
    "- FastAPI avec documentation\n",
    "- Endpoints : `/predict`, `/health`, `/metrics`\n",
    "- Validation des donn√©es\n",
    "\n",
    "### 4. Containerisation\n",
    "- Dockerfile fonctionnel\n",
    "- Image < 500 MB\n",
    "\n",
    "### 5. Monitoring\n",
    "- Dashboard de m√©triques\n",
    "- Alertes automatiques\n",
    "\n",
    "## Livrables\n",
    "\n",
    "1. Code source (GitHub)\n",
    "2. Mod√®le entra√Æn√©\n",
    "3. API fonctionnelle\n",
    "4. Dockerfile\n",
    "5. Documentation\n",
    "6. Pr√©sentation (5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projet final : Template de d√©marrage\n",
    "\n",
    "print(\"üöÄ PROJET FINAL : SYST√àME MLOPS COMPLET\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n√âtapes √† suivre :\")\n",
    "print(\"\\n1Ô∏è‚É£ DONN√âES\")\n",
    "print(\"   - G√©n√©rer ou collecter des donn√©es m√©t√©o\")\n",
    "print(\"   - Features : temp√©rature, humidit√©, pression, vent\")\n",
    "print(\"   - Target : pluie (0/1)\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ MOD√àLE\")\n",
    "print(\"   - Tester plusieurs algorithmes\")\n",
    "print(\"   - Optimiser les hyperparam√®tres\")\n",
    "print(\"   - Tracker avec MLflow\")\n",
    "print(\"   - Sauvegarder le meilleur mod√®le\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ API\")\n",
    "print(\"   - Cr√©er main.py avec FastAPI\")\n",
    "print(\"   - D√©finir les sch√©mas Pydantic\")\n",
    "print(\"   - Impl√©menter /predict, /health, /metrics\")\n",
    "print(\"   - Tester localement\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ DOCKER\")\n",
    "print(\"   - Cr√©er Dockerfile\")\n",
    "print(\"   - Cr√©er requirements.txt\")\n",
    "print(\"   - Build l'image\")\n",
    "print(\"   - Tester le container\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ MONITORING\")\n",
    "print(\"   - Cr√©er dashboard de m√©triques\")\n",
    "print(\"   - D√©finir seuils d'alerte\")\n",
    "print(\"   - Simuler donn√©es de production\")\n",
    "print(\"   - Visualiser les r√©sultats\")\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ DOCUMENTATION\")\n",
    "print(\"   - README.md complet\")\n",
    "print(\"   - Guide d'installation\")\n",
    "print(\"   - Exemples d'utilisation\")\n",
    "print(\"   - Architecture du syst√®me\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üí° Bon courage pour votre projet !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Exercice 5 : Projet final\n",
    "\n",
    "R√©alisez le projet complet en suivant les √©tapes ci-dessus.\n",
    "\n",
    "**Crit√®res d'√©valuation :**\n",
    "- Qualit√© du code (20%)\n",
    "- Performance du mod√®le (20%)\n",
    "- API fonctionnelle (20%)\n",
    "- Containerisation (15%)\n",
    "- Monitoring (15%)\n",
    "- Documentation (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5 : Projet final - √Ä vous de jouer !\n",
    "\n",
    "# TODO: R√©alisez votre projet MLOps complet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì R√©sum√© du module\n",
    "\n",
    "### Ce que vous avez appris\n",
    "\n",
    "1. **MLOps**\n",
    "   - D√©finition et importance\n",
    "   - Diff√©rence avec Data Science\n",
    "   - Applications en RDC\n",
    "\n",
    "2. **Cycle de vie ML**\n",
    "   - Collecte de donn√©es\n",
    "   - Pr√©paration\n",
    "   - Entra√Ænement\n",
    "   - √âvaluation\n",
    "   - D√©ploiement\n",
    "   - Monitoring\n",
    "\n",
    "3. **Outils**\n",
    "   - Git/GitHub (versioning)\n",
    "   - Docker (containerisation)\n",
    "   - MLflow (tracking)\n",
    "   - FastAPI (d√©ploiement)\n",
    "\n",
    "4. **Pratique**\n",
    "   - Cr√©ation d'API REST\n",
    "   - Dockerisation\n",
    "   - Monitoring\n",
    "   - Projet complet\n",
    "\n",
    "### Comp√©tences acquises\n",
    "\n",
    "- ‚úÖ G√©rer le cycle de vie complet d'un mod√®le\n",
    "- ‚úÖ Versionner code et mod√®les\n",
    "- ‚úÖ Cr√©er des APIs de pr√©diction\n",
    "- ‚úÖ Containeriser des applications ML\n",
    "- ‚úÖ Monitorer des mod√®les en production\n",
    "- ‚úÖ Appliquer MLOps √† des cas RDC\n",
    "\n",
    "### Prochaines √©tapes\n",
    "\n",
    "1. **Approfondir**\n",
    "   - Kubernetes pour l'orchestration\n",
    "   - CI/CD avec GitHub Actions\n",
    "   - A/B testing de mod√®les\n",
    "   - Feature stores\n",
    "\n",
    "2. **Pratiquer**\n",
    "   - D√©ployer sur cloud (AWS, GCP, Azure)\n",
    "   - Cr√©er des pipelines automatis√©s\n",
    "   - Monitorer en production r√©elle\n",
    "\n",
    "3. **Certifications**\n",
    "   - AWS Certified Machine Learning\n",
    "   - Google Cloud Professional ML Engineer\n",
    "   - MLOps Specialization (Coursera)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Ressources suppl√©mentaires\n",
    "\n",
    "### Documentation\n",
    "- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)\n",
    "- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n",
    "- [Docker Documentation](https://docs.docker.com/)\n",
    "\n",
    "### Cours en ligne\n",
    "- MLOps Specialization (DeepLearning.AI)\n",
    "- Machine Learning Engineering for Production (Coursera)\n",
    "- Full Stack Deep Learning\n",
    "\n",
    "### Livres\n",
    "- \"Designing Machine Learning Systems\" - Chip Huyen\n",
    "- \"Building Machine Learning Powered Applications\" - Emmanuel Ameisen\n",
    "- \"Machine Learning Engineering\" - Andriy Burkov\n",
    "\n",
    "### Communaut√©s\n",
    "- Reddit r/MLOps\n",
    "- MLOps Community Slack\n",
    "- LinkedIn MLOps groups\n",
    "\n",
    "---\n",
    "\n",
    "**F√©licitations ! Vous avez termin√© le module MLOps ! üéâ**\n",
    "\n",
    "*Continuez √† pratiquer et √† d√©ployer vos mod√®les en production !*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
